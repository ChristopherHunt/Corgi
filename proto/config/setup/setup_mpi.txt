# Simple operations that work on a single node
mpiicc simple_query.cpp -o simple_query
mpirun -n 2 ./simple_query -iface eth0

# What I tried to get nodes to talk to one another:
source /opt/intel/bin/compilervars.sh intel64
source /opt/intel/compilers_and_libraries_2016.0.109/linux/mpi/intel64/bin/mpivars.sh

# I created the machines.LINUX file with the following contents:
csc127x01.ad.calpoly.edu
csc127x02.ad.calpoly.edu

# I added mappings to my ~/.ssh/config file for each of the above addresses
csc127x01.ad.calpoly.edu -> chhunt@csc127x01.csc.calpoly.edu
csc127x02.ad.calpoly.edu -> chhunt@csc127x02.csc.calpoly.edu

# I ran 
./opt/intel/parallel_studio_xe_2016.0.047/bin/sshconnectivity.exp ~/machines.LINUX
# which was able to successfully complete.

# I ran
mpirun -n 2 -ppn 1 -f ./machines.LINUX ./myprog -iface eth0
# and got the following output:

[proxy:0:1@csc127x02.ad.calpoly.edu] HYDU_sock_connect (../../utils/sock/sock.c:224): unable to get host address for csc127x01.ad.calpoly.edu (1)
[proxy:0:1@csc127x02.ad.calpoly.edu] main (../../pm/pmiserv/pmip.c:415): unable to connect to server csc127x01.ad.calpo

# It seems like the difference between the outward facing published IP binding for each node (aka having the .csc. name instead of the .ad. name and having a leading csc instead of an embedded one) is what is being troublesome here. However, it seems like MPI requires the name to match the first entry in the /etc/hosts file for each node, and I didn't want to go changing that.

# If I change the entries in the machines.LINUX file to be
127x01.csc.calpoly.edu
127x02.csc.calpoly.edu

# then everything hangs when I try to run mpirun (presumably because there isn't a key mapping between the 2 sets of nodes which is leading to password issues?).

# also noticed that when I run an mpi program I get the following warnings:
DAPL startup: RLIMIT_MEMLOCK too small

# a quick ulimit -a shows:
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 95595
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited

# where intel suggests
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 256273
max locked memory       (kbytes, -l) unlimited
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) unlimited
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited

# the main differences being
pending signals                 (-i) 95595 vs 256273
max locked memory       (kbytes, -l) 64 vs unlimited
stack size              (kbytes, -s) 10240 vs unlimited
